{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertFlorinus/mnistcnn/blob/master/notebook/trainingcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0eCVBO0zGD0T"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import rotate\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam, Adadelta\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import LearningRateScheduler, CSVLogger\n",
        "from cv2 import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sgue2U8lGeqV"
      },
      "outputs": [],
      "source": [
        "# gathering the mnist-dataset, train is used for training,\n",
        "# test is used to predict images previously unseen,\n",
        "# we do this to ensure overfitting has not occurred,\n",
        "# y are labels to X which are the images\n",
        "\n",
        "(X_traine, Y_train), (X_teste, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "87kQJZqfJq1F"
      },
      "outputs": [],
      "source": [
        "#upscaling the mnist dataset from 28x28 pixel images to 112x112\n",
        "#this is a bandaid fix but helps with preprocessing real images outside mnist\n",
        "X_train = np.empty((60000,112,112))\n",
        "X_test = np.empty((10000,112,112))\n",
        "for i in range(60000):\n",
        "  imgs = X_traine[i]\n",
        "  enlargeder = cv2.resize(imgs, (112, 112), interpolation=cv2.INTER_AREA)\n",
        "  X_train[i,:,:] = enlargeder\n",
        "\n",
        "for i in range(10000):\n",
        "  imgs = X_teste[i]\n",
        "  enlargeder = cv2.resize(imgs, (112, 112), interpolation=cv2.INTER_AREA)\n",
        "  X_test[i,:,:] = enlargeder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "erY8V30VGe6Z"
      },
      "outputs": [],
      "source": [
        "# reshaping for keras compatibility\n",
        "X_train = X_train.reshape(X_train.shape[0], 112, 112, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 112, 112, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uWM5pMH8GmOy"
      },
      "outputs": [],
      "source": [
        "# changing datatype from uint8 to float32,\n",
        "# this is to allow for normalizising the pixel value,\n",
        "# between 0 and 1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing pixels\n",
        "X_train/=255\n",
        "X_test/=255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B4ycgaHtGp2n"
      },
      "outputs": [],
      "source": [
        "# one-hot-encoding the outputs, or in simpler terms,\n",
        "# storing the outputs as a vector of 1x10\n",
        "number_of_classes = 10\n",
        "Y_train = np_utils.to_categorical(Y_train, number_of_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, number_of_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECkrZBliI4lA",
        "outputId": "f14baf69-c825-4710-8b2a-c1cff7ccf677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 10) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBNpe2VvKqXl",
        "outputId": "2243aab9-1a11-457a-8f39-8530ecc94fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 112, 112, 1) (10000, 112, 112, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RSx-lzATGR3U"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pk1i9ODrG0A9"
      },
      "outputs": [],
      "source": [
        "# each convolutional/conv layer distorts the input arrays\n",
        "# each model.add creates a new layer in the network\n",
        "# adding a spatial convolutional/conv layer and \n",
        "# declaring input shape required for the img array\n",
        "# input shape value only needed for first conv\n",
        "# 32 for the amount of filters and thus also feature maps outputed,\n",
        "# (3,3) for filter size, default stride is 1\n",
        "\n",
        "model.add(Conv2D(16, (20,20), strides = 2, activation=\"relu\", input_shape=(112,112,1), padding=\"same\"))\n",
        "model.add(Conv2D(16, (10,10), strides = 2, activation=\"relu\", padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "# adding a batchnormalization layer to reduce a batchs covariant shift,\n",
        "# normalizing the images to execute more effectively,\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# adding conv layer with 5x5 filter and a stride of 2 instead of max pooling,\n",
        "# downsampling image but retaining import data for classification.\n",
        "model.add(Conv2D(32, (5,5), strides=2, padding=\"same\",activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# using dropout with a rate 0f 0.4, this randomly \"drops\",\n",
        "# 40% of the nodes to a output value of 0 each iteration, which helps prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# raise amount from 32 to 64\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (5,5), strides=2, padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# flattening the input to a 1d array,\n",
        "# flattening the pixel data of 64 4x4 arrays\n",
        "# to a 1d array containing 1024 pixel values,\n",
        "# not 1024 pixels of the original image but of the,\n",
        "# outputs from the convolutional neural network\n",
        "# this ends the spatial/convolutional part of the network\n",
        "model.add(Flatten())\n",
        "\n",
        "# adding a fully connected layer of 128 neurons\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Final layer of 10 neurons with a softmax activation,\n",
        "# this outputs a prediction (number with highest activation value)\n",
        "model.add(Dense(number_of_classes, activation=\"softmax\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ijss7shQHDE5"
      },
      "outputs": [],
      "source": [
        "# Declaring loss function and optimizer,\n",
        "# Adam is an enhancement of SGD.\n",
        "# Accuracy metric for us to get results for evaluating the model \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gEdcqQBhGMW3"
      },
      "outputs": [],
      "source": [
        "# Number of images to iterate simultaneously before each weight update\n",
        "batchsize = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QZgyxlzyP-1t"
      },
      "outputs": [],
      "source": [
        "X_val = X_test[9000:]\n",
        "Y_val = Y_test[9000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z9M1uywOVEqF"
      },
      "outputs": [],
      "source": [
        "X_test = X_test[:9000]\n",
        "Y_test = Y_test[:9000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld0kqmXyQM-H",
        "outputId": "af44d1b4-6ea9-4358-c5de-d35ee202d1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9000, 112, 112, 1) (9000, 10)\n",
            "(1000, 112, 112, 1) (1000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(X_test.shape, Y_test.shape)\n",
        "print(X_val.shape, Y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aeIBu7mrHH6Z"
      },
      "outputs": [],
      "source": [
        "# Augmentning training data for better generalisation,\n",
        "# and prevent overfitting\n",
        "gen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.15)\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0NGJFJb2VPAr"
      },
      "outputs": [],
      "source": [
        "testing_generator = gen.flow(X_test, Y_test, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "V1xXTUZCHObY"
      },
      "outputs": [],
      "source": [
        "# Reducing learning rate to 95% of the last epoch,\n",
        "# speeding up convergence by keeping weight updates smaller as the model,\n",
        "# approaches convergence.\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "txK7a0ZLG_-M"
      },
      "outputs": [],
      "source": [
        "# Log file for tracking information about the learning process and its metrics\n",
        "csv_logger = CSVLogger(\"training_test.log\", append=True, separator=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIj9Df2WMtCS",
        "outputId": "202d161f-905d-4329-9e75-ea0747a8b414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "937/937 [==============================] - 124s 81ms/step - loss: 0.7984 - accuracy: 0.7572 - val_loss: 0.1488 - val_accuracy: 0.9536\n",
            "Epoch 2/10\n",
            "937/937 [==============================] - 74s 78ms/step - loss: 0.1278 - accuracy: 0.9619 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
            "Epoch 3/10\n",
            "937/937 [==============================] - 73s 78ms/step - loss: 0.0990 - accuracy: 0.9705 - val_loss: 0.0593 - val_accuracy: 0.9802\n",
            "Epoch 4/10\n",
            "937/937 [==============================] - 75s 80ms/step - loss: 0.0749 - accuracy: 0.9783 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
            "Epoch 5/10\n",
            "937/937 [==============================] - 73s 78ms/step - loss: 0.0716 - accuracy: 0.9789 - val_loss: 0.0398 - val_accuracy: 0.9878\n",
            "Epoch 6/10\n",
            "937/937 [==============================] - 73s 78ms/step - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.0333 - val_accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "937/937 [==============================] - 72s 77ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.0401 - val_accuracy: 0.9882\n",
            "Epoch 8/10\n",
            "937/937 [==============================] - 70s 75ms/step - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.0314 - val_accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "937/937 [==============================] - 70s 75ms/step - loss: 0.0492 - accuracy: 0.9853 - val_loss: 0.0299 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "937/937 [==============================] - 70s 75ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0373 - val_accuracy: 0.9894\n"
          ]
        }
      ],
      "source": [
        "# starting training, validation_data is mnist data not trained on,\n",
        "# to ensure us we arent overfitting to the training set but actually generalising\n",
        "history = model.fit(train_generator,steps_per_epoch=X_train.shape[0]//batchsize, epochs=10, \n",
        "                  validation_data=testing_generator, callbacks=[annealer, csv_logger], verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BbDlvbVnHW5h"
      },
      "outputs": [],
      "source": [
        "model.save(\"ALnet-3.0.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_lsTHyAHY9b",
        "outputId": "f2f1b953-11be-4695-bdec-17dbde8d4e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 1s 13ms/step - loss: 0.0446 - accuracy: 0.9920\n",
            "Test loss:  0.04459251090884209\n",
            "Test accuracy:  0.9919999837875366\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x=X_val, y=Y_val, verbose=1)\n",
        "print(\"Test loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKTU3Ken6X7E",
        "outputId": "d7fd0f95-32d2-4025-b873-50c2ba955fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 56, 56, 16)\n",
            "(None, 28, 28, 16)\n",
            "(None, 26, 26, 32)\n",
            "(None, 26, 26, 32)\n",
            "(None, 24, 24, 32)\n",
            "(None, 24, 24, 32)\n",
            "(None, 12, 12, 32)\n",
            "(None, 12, 12, 32)\n",
            "(None, 12, 12, 32)\n",
            "(None, 10, 10, 64)\n",
            "(None, 10, 10, 64)\n",
            "(None, 8, 8, 64)\n",
            "(None, 8, 8, 64)\n",
            "(None, 4, 4, 64)\n",
            "(None, 4, 4, 64)\n",
            "(None, 4, 4, 64)\n",
            "(None, 1024)\n",
            "(None, 128)\n",
            "(None, 128)\n",
            "(None, 128)\n",
            "(None, 10)\n"
          ]
        }
      ],
      "source": [
        "# printing Alnet-3.0 structure \n",
        "for layer in model.layers:\n",
        "  print(layer.output_shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPpBEZAPkZc1HKfXyrVxBd+",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "trainingcode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
